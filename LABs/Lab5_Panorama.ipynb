{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d'un panorama\n",
    "\n",
    "L'objectif de ce TP est de créer un panorama à partir de plusieurs images, en utilisant les principales notions vues en cours. On essaiera de construire des panoramas d'images de l'école (intérieur ou extérieur) et votre premier travail consistera donc à faire un série de clichés (à l'aide de votre téléphone par exemple) de la partie de l'école que vous souhaitez *reconstruire*. Il faudra bien faire attention à faire en sorte que vos images se recouvrent partiellement.\n",
    "\n",
    "Le principe est relativement simple et suit l'approche vue en cours :\n",
    "\n",
    " + Une première étape est de décider quelle sera votre image source et quelles seront vos images destination (i.e les images que vous voulez mettre en correspondance avec votre image source).\n",
    " \n",
    " + Une fois l'image source choisie, une technique pour la création de panorama est de placer cette image dans un plus gros canevas (image de plus grande taille dont les pixels non connus seront mis à noir). La fonction [**warpAffine**]( https://docs.opencv.org/3.4.0/da/d6e/tutorial_py_geometric_transformations.html) d'OpenCV pourrait être utilisée pour cela.\n",
    "\n",
    " + L'étape d'après consiste à la détection et à la description d'un ensembles de points caractéristiques pour l'image cible transformée et l'ensemble des images destination. Vous pourrez pour cela utiliser les descripteurs [SIFT](https://docs.opencv.org/3.3.0/da/df5/tutorial_py_sift_intro.html).\n",
    " \n",
    " + Il s'agira ensuite de mettre en correspondance les descripteurs de l'image source avec ceux de l'image destination. Ici aussi vous pouvez utiliser plusieurs outils de [matching](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.html) fournis par la bibliothèque OpenCV.\n",
    " \n",
    " + Seuls les 200 meilleures mises en correspondance seront gardées pour la suite.\n",
    " \n",
    " + A partir de ces mises en correspondance, il faut ensuite calculer l'homographie permettant de passer de l'image sources à l'image destination. Seuls 4 mises en correspondance sont nécessaire pour calculer cette homographie mais il est usuel d'en utiliser plus avec l'approche RANSAC expliquer très simplement [ici](http://eric-yuan.me/ransac/) et disponible dans Opencv (documentation [ici](https://docs.opencv.org/3.4.0/d9/dab/tutorial_homography.html)) comme un paramètre de la fonction **findHomography**).\n",
    " \n",
    " + Appliquer l'homographie obtenue à l'image destination.\n",
    " \n",
    " + Fusionner l'image cible et l'image destination.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# ETAPE 1\n",
    "\n",
    "\n",
    "\n",
    "# ETAPE 2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ETAPE 3 : matching\n",
    "\n",
    "\n",
    "\n",
    "# ETAPE 4\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
